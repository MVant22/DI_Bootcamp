{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise_XP_3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n",
    "users = pd.read_csv(url, sep='|')\n",
    "\n",
    "print(users.columns)\n",
    "\n",
    "print(users.groupby('occupation')['age'].mean())\n",
    "\n",
    "# Exercise_XP_Gold\n",
    "\n",
    "# With the ‘users’ DataFrame from XP, determine the male ratio per occupation,\n",
    "# and sort the results in descending order.\n",
    "users['is_male'] = users['gender'].apply(lambda x:1 if x == 'M' else 0)\n",
    "\n",
    "male_ratio = users.groupby('occupation')['is_male'].mean()\n",
    "\n",
    "male_ratio_sorted = male_ratio.sort_values(ascending=False)\n",
    "\n",
    "print(f\"sorted male {male_ratio_sorted}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# For each occupation, calculate the minimum and maximum ages using groupby() and agg().\n",
    "# min_age = users['age'].min()\n",
    "# max_age = users['age'].max()\n",
    "# print(f\"minimum age: {min_age}\")\n",
    "# print(f\"Maximum age: {max_age}\")\n",
    "\n",
    "age_stats = users.groupby('occupation')['age'].agg(['min', 'max'])\n",
    "\n",
    "print(age_stats)\n",
    "\n",
    "print()\n",
    "# For each combination of occupation and gender, calculate the mean age using groupby().\n",
    "mean_age = users.groupby(['occupation', 'gender'])['age'].mean()\n",
    "print(mean_age)\n",
    "\n",
    "print()\n",
    "# Present the percentage of women and men in each occupation.\n",
    "gender_percent = users.groupby('occupation')['gender'].value_counts(normalize=True).unstack() * 100\n",
    "\n",
    "gender_percent = gender_percent.round(1)\n",
    "\n",
    "print(gender_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366b2d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise XP 4\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie']\n",
    "})\n",
    "\n",
    "data2 = pd.DataFrame({\n",
    "    'ID': [4, 5, 6],\n",
    "    'Name': ['David', 'Eva', 'Frank']\n",
    "})\n",
    "\n",
    "# data3\n",
    "data3 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3],\n",
    "    'Score': [85, 92, 78]\n",
    "})\n",
    "\n",
    "all_data_rows = pd.concat([data1, data2], ignore_index=True)\n",
    "print(all_data_rows)\n",
    "\n",
    "print()\n",
    "\n",
    "all_data_col = pd.concat([data1, data2], axis=1)\n",
    "print(all_data_col)\n",
    "\n",
    "print()\n",
    "# Exercises_XP_Gold\n",
    "# Print ‘data3’ from the XP section.\n",
    "print(data3)\n",
    "\n",
    "# Use merge() to combine ‘all_data’ and ‘data3’.\n",
    "# Make sure that both DataFrames have a column named ‘subject_id’ to merge on.\n",
    "# merged_all_data = pd.merge(all_data_rows, data3, on='subject_id')\n",
    "# print(merged_all_data)\n",
    "\n",
    "if 'subject_id' in all_data_rows.columns and 'subject_id' in data3.columns:\n",
    "    merged_inner = pd.merge(all_data_rows, data3, on='subject_id', how='inner')\n",
    "    print(merged_inner)\n",
    "else:\n",
    "    print(\"One of the DataFrames does not have the column 'subject_id'\")\n",
    "\n",
    "# Use merge() to combine only the data that has the same ‘subject_id’ on both ‘data1’ and ‘data2’.\n",
    "# merged_data = pd.merge(data1, data2, on='subject_id', how='inner')\n",
    "# print(merged_data)\n",
    "print(data1.columns)\n",
    "print(data2.columns)\n",
    "\n",
    "data1.columns = data1.columns.str.strip()\n",
    "data2.columns = data2.columns.str.strip()\n",
    "\n",
    "if 'subject_id' in data1.columns and 'subject_id' in data2.columns:\n",
    "    merged_inner = pd.merge(data1, data2, on='subject_id', how='inner')\n",
    "    print(merged_inner)\n",
    "else:\n",
    "    print(\"One of the DataFrames does not have the column 'subject_id'\")\n",
    "\n",
    "\n",
    "# Merge all values in ‘data1’ and ‘data2’, keeping records from both sides where available.\n",
    "if 'subject_id' in data1.columns and 'subject_id' in data2.columns:\n",
    "    merged_inner = pd.merge(data1, data2, on='subject_id', how='outer')\n",
    "    print(merged_inner)\n",
    "else:\n",
    "    print(\"One of the DataFrames does not have the column 'subject_id'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210fee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise_XP_5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris = pd.read_csv(url, header=None)\n",
    "\n",
    "iris.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "\n",
    "print(iris.isnull().sum())\n",
    "\n",
    "# Exercise_XP_Gold\n",
    "\n",
    "# In the ‘iris’ DataFrame from XP, assign NaN to the ‘petal_length’ column for rows 10 to 29.\n",
    "petal_length = iris.loc[10:29, 'petal_length'] = np.nan\n",
    "print(petal_length)\n",
    "\n",
    "# Replace the NaN values in ‘petal_length’ with 1.0 using the fillna() function.\n",
    "df_filled = iris.fillna(1.0)\n",
    "print(df_filled)\n",
    "\n",
    "# Delete the ‘class’ column from the DataFrame using the drop() function.\n",
    "# df_dropped_col = iris.drop(columns=['class'])\n",
    "# print(df_dropped_col)\n",
    "\n",
    "# Set the first three rows to NaN using np.nan.\n",
    "iris.loc[0:2, :] = np.nan\n",
    "print(iris.head(3))\n",
    "\n",
    "# Remove any rows with NaN values using the dropna() method.\n",
    "df_cleaned_all = iris.dropna(how='all')\n",
    "print(df_cleaned_all)\n",
    "\n",
    "# Reset the index of ‘iris’ so that it starts from 0 again using the reset_index() function.\n",
    "# To avoid adding the old index as a new column, use the drop=True parameter.\n",
    "print(iris.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf296679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise_XP_6\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'evolution': ['Ivysaur', 'Charmeleon', 'Wartortle', 'Metapod'],\n",
    "    'hp': [45, 39, 44, 45],\n",
    "    'name': ['Bulbasaur', 'Charmander', 'Squirtle', 'Caterpie'],\n",
    "    'pokedex': ['yes', 'no', 'yes', 'no'],\n",
    "    'type': ['grass', 'fire', 'water', 'bug']\n",
    "})\n",
    "\n",
    "df = df[['name', 'type', 'hp', 'evolution', 'pokedex']]\n",
    "print(df)\n",
    "\n",
    "# Exercises_XP_Gold\n",
    "# Display the ‘Pokémon’ DataFrame from XP.\n",
    "print(df)\n",
    "\n",
    "# Add a new column called ‘place’ to ‘Pokémon’ with default values as ‘park’.\n",
    "df['place'] = ['park', '', '', '']\n",
    "print(df)\n",
    "\n",
    "print()\n",
    "# Display the data type of each column in ‘Pokémon’.\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ce63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise_XP_7\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/US_Baby_Names/US_Baby_Names_right.csv'\n",
    "baby_names = pd.read_csv(url)\n",
    "\n",
    "print(baby_names.head(10))\n",
    "\n",
    "# baby_names = baby_names.drop(['Unnamed: 0', 'Id'], axis=1)\n",
    "#\n",
    "# print(baby_names.columns)\n",
    "\n",
    "# baby_names = baby_names.drop(['Id'], axis=1)\n",
    "\n",
    "# Exercises_XP_Gold\n",
    "\n",
    "# From the ‘baby_names’ DataFrame in XP, count the number of genders.\n",
    "gender_count = baby_names['Gender'].value_counts()\n",
    "print(gender_count)\n",
    "\n",
    "# Group the data on ‘Year’ and ‘Gender’ and find the sum of ‘Count’ for each group.\n",
    "counter_year_gender = baby_names.groupby(['Year', 'Gender'])['Count'].sum()\n",
    "print(counter_year_gender)\n",
    "\n",
    "# Determine the names with most occurrences.\n",
    "most_names = baby_names.groupby('Name')['Count'].sum().sort_values(ascending=False)\n",
    "print(most_names)\n",
    "\n",
    "# Determine the median name occurrence in the dataset.\n",
    "name_counts = baby_names['Name'].value_counts()\n",
    "median = name_counts.median()\n",
    "print(median)\n",
    "\n",
    "# Determine the distribution of male and female born count by states\n",
    "gender_state_distribution = baby_names.groupby(['State', 'Gender'])['Count'].sum().unstack()\n",
    "print(gender_state_distribution)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
